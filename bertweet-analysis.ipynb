{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 讀取專用的 Tokenizer (BERTweet有提供專用的Normalization方式)\n",
    "- Model 1: bertweet-base (BERTweet)\n",
    "- Model 2: bertweet-covid19-base-uncased (BERTweet)\n",
    "- Model 3: twitter-xlm-roberta-base (XLM-T)\n",
    "- Model 4: twitter-roberta-base (TWEETEVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T09:51:33.1502Z",
     "iopub.status.busy": "2022-01-18T09:51:33.150011Z",
     "iopub.status.idle": "2022-01-18T09:51:48.127166Z",
     "shell.execute_reply": "2022-01-18T09:51:48.126425Z",
     "shell.execute_reply.started": "2022-01-18T09:51:33.15017Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", normalization=True)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-covid19-base-uncased\", normalization=True)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2: 如果使用的是 vinai 的模型，他有整合了normalization (tweet preprocessing)在 tokenizer 之中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n",
    "df = df.rename({'target':'label'}, axis = 1)\n",
    "df = df[['text', 'label']]\n",
    "\n",
    "### 切記 Test dataset 和 Train dataset 要有一模一樣的 preprocessing\n",
    "df_test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n",
    "df_test = df_test[['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3: 如果是使用 cardiffnlp 的模型，就要對 Tweets preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(text):\n",
    "#     new_text = []\n",
    "#     for t in text.split(\" \"):\n",
    "#         t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "#         t = 'http' if t.startswith('http') else t\n",
    "#         new_text.append(t)\n",
    "#     return \" \".join(new_text)\n",
    "# df['text'] = df['text'].apply(lambda x: preprocess(x))\n",
    "# df_test['text'] = df_test['text'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-4: 將處理完的資料存到CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T09:51:48.129005Z",
     "iopub.status.busy": "2022-01-18T09:51:48.128598Z",
     "iopub.status.idle": "2022-01-18T09:51:48.335736Z",
     "shell.execute_reply": "2022-01-18T09:51:48.33504Z",
     "shell.execute_reply.started": "2022-01-18T09:51:48.128968Z"
    }
   },
   "outputs": [],
   "source": [
    "### Shuffle the training data\n",
    "df = df.sample(frac = 1)\n",
    "df.to_csv('train_processed.csv')\n",
    "df_test.to_csv('test_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: 使用 Huggingface 的 datasets module來讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T09:51:48.338349Z",
     "iopub.status.busy": "2022-01-18T09:51:48.338096Z",
     "iopub.status.idle": "2022-01-18T09:51:51.490723Z",
     "shell.execute_reply": "2022-01-18T09:51:51.489899Z",
     "shell.execute_reply.started": "2022-01-18T09:51:48.338315Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "### Split the training data into train (90%) and validation (10%)\n",
    "train_dataset = load_dataset('csv', data_files='train_processed.csv', split='train[:90%]')\n",
    "val_dataset = load_dataset('csv', data_files='train_processed.csv', split='train[90%:]')\n",
    "test_dataset = load_dataset('csv', data_files='test_processed.csv', split = 'train')\n",
    "### Padding or truncating the data to 100 tokens\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", max_length=100)\n",
    "tokenized_datasets_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets_val = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets_test = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: 使用 Huggingface 來讀取想要用的Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T09:51:51.492432Z",
     "iopub.status.busy": "2022-01-18T09:51:51.492086Z",
     "iopub.status.idle": "2022-01-18T09:52:28.179661Z",
     "shell.execute_reply": "2022-01-18T09:52:28.178998Z",
     "shell.execute_reply.started": "2022-01-18T09:51:51.492394Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-large\", num_labels=2)\n",
    "# model2 = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-covid19-base-uncased\", num_labels=2)\n",
    "# model3 = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\", num_labels=2)\n",
    "# model4 = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T09:52:28.181342Z",
     "iopub.status.busy": "2022-01-18T09:52:28.18108Z",
     "iopub.status.idle": "2022-01-18T09:52:28.210814Z",
     "shell.execute_reply": "2022-01-18T09:52:28.210177Z",
     "shell.execute_reply.started": "2022-01-18T09:52:28.181305Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.定義訓練過程的參數\n",
    "- Batch_size = 32\n",
    "- gradient_accumulation_steps = 8  \n",
    "代表著處理 32*8 = 256 筆資料之後才會做一次back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T09:52:28.212363Z",
     "iopub.status.busy": "2022-01-18T09:52:28.212058Z",
     "iopub.status.idle": "2022-01-18T09:52:32.447611Z",
     "shell.execute_reply": "2022-01-18T09:52:32.446744Z",
     "shell.execute_reply.started": "2022-01-18T09:52:28.212328Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "adafactor=False,\n",
    "adam_beta1=0.9,\n",
    "adam_beta2=0.999,\n",
    "adam_epsilon=1e-08,\n",
    "do_predict=False,\n",
    "do_train=False,\n",
    "eval_accumulation_steps=None,\n",
    "gradient_accumulation_steps=8,\n",
    "greater_is_better=None,\n",
    "group_by_length=False,\n",
    "ignore_data_skip=False,\n",
    "label_names=None,\n",
    "label_smoothing_factor=0.0,\n",
    "learning_rate=5e-05,\n",
    "load_best_model_at_end=False,\n",
    "local_rank=-1,\n",
    "max_grad_norm=1.0,\n",
    "max_steps=-1,\n",
    "no_cuda=False,\n",
    "num_train_epochs=10.0,\n",
    "output_dir=\"training_res\",\n",
    "overwrite_output_dir=False,\n",
    "past_index=-1,\n",
    "per_device_eval_batch_size=32,\n",
    "per_device_train_batch_size=32,\n",
    "prediction_loss_only=False,\n",
    "remove_unused_columns=True,\n",
    "resume_from_checkpoint=None,\n",
    "save_on_each_node=False,\n",
    "save_steps = 100,\n",
    "save_total_limit=None,\n",
    "seed=42,\n",
    "sharded_ddp=[],\n",
    "skip_memory_metrics=True,\n",
    "tpu_metrics_debug=False,\n",
    "tpu_num_cores=None,\n",
    "use_legacy_prediction_loop=False,\n",
    "warmup_ratio=0.0,\n",
    "warmup_steps=0,\n",
    "weight_decay=0.0,\n",
    "xpu_backend=None,\n",
    "evaluation_strategy = \"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 定義 Model 訓練的參數、資料，以及Metric的計算方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T09:52:32.449787Z",
     "iopub.status.busy": "2022-01-18T09:52:32.449298Z",
     "iopub.status.idle": "2022-01-18T09:52:39.024369Z",
     "shell.execute_reply": "2022-01-18T09:52:39.022976Z",
     "shell.execute_reply.started": "2022-01-18T09:52:32.449748Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args, train_dataset=tokenized_datasets_train, eval_dataset=tokenized_datasets_val, compute_metrics=compute_metrics, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T09:52:39.026319Z",
     "iopub.status.busy": "2022-01-18T09:52:39.026054Z",
     "iopub.status.idle": "2022-01-18T10:30:10.046981Z",
     "shell.execute_reply": "2022-01-18T10:30:10.046043Z",
     "shell.execute_reply.started": "2022-01-18T09:52:39.026279Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 讀取最好的模型，並預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T10:30:10.048834Z",
     "iopub.status.busy": "2022-01-18T10:30:10.048551Z",
     "iopub.status.idle": "2022-01-18T10:30:10.924242Z",
     "shell.execute_reply": "2022-01-18T10:30:10.92253Z",
     "shell.execute_reply.started": "2022-01-18T10:30:10.048793Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./training_res/path-to-best-model\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-18T10:30:10.930889Z",
     "iopub.status.idle": "2022-01-18T10:30:10.93165Z",
     "shell.execute_reply": "2022-01-18T10:30:10.931437Z",
     "shell.execute_reply.started": "2022-01-18T10:30:10.93141Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_datasets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-18T10:30:10.939174Z",
     "iopub.status.idle": "2022-01-18T10:30:10.94098Z",
     "shell.execute_reply": "2022-01-18T10:30:10.940726Z",
     "shell.execute_reply.started": "2022-01-18T10:30:10.94068Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-18T10:30:10.94386Z",
     "iopub.status.idle": "2022-01-18T10:30:10.944612Z",
     "shell.execute_reply": "2022-01-18T10:30:10.944401Z",
     "shell.execute_reply.started": "2022-01-18T10:30:10.944372Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_sub = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-18T10:30:10.945735Z",
     "iopub.status.idle": "2022-01-18T10:30:10.946473Z",
     "shell.execute_reply": "2022-01-18T10:30:10.946268Z",
     "shell.execute_reply.started": "2022-01-18T10:30:10.946243Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sub['target'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-18T10:30:10.947577Z",
     "iopub.status.idle": "2022-01-18T10:30:10.948344Z",
     "shell.execute_reply": "2022-01-18T10:30:10.948124Z",
     "shell.execute_reply.started": "2022-01-18T10:30:10.948098Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sub.to_csv('/kaggle/working/bertweet-large-submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-18T10:30:10.94981Z",
     "iopub.status.idle": "2022-01-18T10:30:10.950627Z",
     "shell.execute_reply": "2022-01-18T10:30:10.950417Z",
     "shell.execute_reply.started": "2022-01-18T10:30:10.950392Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'/kaggle/working/bertweet_submission_epoch2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
